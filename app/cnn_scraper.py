# cnn_scraper.py
import requests
from bs4 import BeautifulSoup
from newspaper import Article
from transformers import pipeline
from datetime import datetime
import json
import time
import os  # KlasÃ¶r oluÅŸturmak iÃ§in os modÃ¼lÃ¼nÃ¼ ekledik

# === YENÄ° EKLENEN KISIM ===
# OluÅŸturduÄŸumuz dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ modÃ¼lÃ¼nden fonksiyonu import ediyoruz
from converter_module import json_to_csv
# ==========================

# Summarizer modelini baÅŸlat
# Not: Ä°lk Ã§alÄ±ÅŸtÄ±rmada model indirileceÄŸi iÃ§in biraz zaman alabilir.
print("Summarizer modeli yÃ¼kleniyor...")
summarizer = pipeline(
    "summarization",
    model="facebook/bart-large-cnn",
    device=-1  # CPU kullanÄ±mÄ± iÃ§in, GPU varsa 0 yapabilirsiniz
)
print("Model yÃ¼klendi.")


# CNN'den haber linklerini Ã§eker
def get_cnn_articles(max_articles=5):
    url = "https://edition.cnn.com/business"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status() # Hata durumunda exception fÄ±rlat
    except requests.exceptions.RequestException as e:
        print(f"Hata: CNN ana sayfasÄ±na ulaÅŸÄ±lamadÄ±. {e}")
        return []

    soup = BeautifulSoup(response.content, "html.parser")

    article_links = []
    # CNN'in yapÄ±sÄ± deÄŸiÅŸebileceÄŸi iÃ§in daha spesifik bir arama yapalÄ±m
    for container in soup.find_all('div', {'class': 'container__item'}):
        link_tag = container.find('a', {'data-link-type': 'article'})
        if link_tag and 'href' in link_tag.attrs:
            href = link_tag['href']
            if href.startswith('/'):
                full_url = "https://edition.cnn.com" + href
                if full_url not in article_links:
                    article_links.append(full_url)
        if len(article_links) >= max_articles:
            break
            
    return article_links

# Tekil bir makaleyi indirip Ã¶zetler
def scrape_article(url):
    try:
        article = Article(url)
        article.download()
        article.parse()

        text = article.text.strip()
        if len(text) < 200: # Ã–zetlenemeyecek kadar kÄ±sa metinleri atla
            return None

        # Metni modele uygun boyuta getir
        summary = summarizer(text[:1024], max_length=150, min_length=40, do_sample=False)[0]['summary_text']
        
        return {
            "source": "cnn",
            "url": url,
            "title": article.title,
            "summary": summary,
            "published": article.publish_date.isoformat() if article.publish_date else datetime.utcnow().isoformat()
        }
    except Exception as e:
        print(f"Makale iÅŸlenirken hata oluÅŸtu ({url}): {e}")
        return None

# Makaleleri toplar ve JSON dosyasÄ±na kaydeder
def collect_and_save_cnn_data(out_dir="Data", max_articles=5):
    # Data klasÃ¶rÃ¼ yoksa oluÅŸtur
    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    json_out_path = os.path.join(out_dir, "cnn_data.json")
    articles = []
    urls = get_cnn_articles(max_articles=max_articles)
    
    if not urls:
        print("HiÃ§ makale linki bulunamadÄ±. Ä°ÅŸlem durduruluyor.")
        return

    for url in urls:
        print(f"Ä°ÅŸleniyor: {url}")
        data = scrape_article(url)
        if data:
            articles.append(data)
            print(f"âœ… ToplandÄ±: {data['title']}")
        else:
            print(f"âŒ AtlandÄ±: {url}")
        time.sleep(1.5)  # engellenmemek iÃ§in bekle

    if not articles:
        print("HiÃ§bir makale baÅŸarÄ±yla iÅŸlenemedi.")
        return

    with open(json_out_path, "w", encoding="utf-8") as f:
        json.dump(articles, f, ensure_ascii=False, indent=2)
    print(f"\nðŸŽ‰ {len(articles)} makale {json_out_path} dosyasÄ±na kaydedildi.")

    # === YENÄ° EKLENEN KISIM ===
    # JSON kaydÄ± bittikten sonra CSV'ye dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemini Ã§aÄŸÄ±rÄ±yoruz
    print("\nCSV formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
    csv_out_path = json_out_path.replace(".json", ".csv")
    
    if json_to_csv(json_out_path, csv_out_path):
        print(f"âœ… BaÅŸarÄ±lÄ±! Veriler {csv_out_path} dosyasÄ±na da kaydedildi.")
    else:
        print("âŒ CSV dÃ¶nÃ¼ÅŸtÃ¼rme sÄ±rasÄ±nda bir hata oluÅŸtu.")
    # ==========================


# Dosya doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda Ã§alÄ±ÅŸsÄ±n
if __name__ == "__main__":
    # Ã–rnek olarak 3 makale Ã§ekelim
    collect_and_save_cnn_data(max_articles=50)